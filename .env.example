# Admin Credentials
# ‚ö†Ô∏è WICHTIG: √Ñndere das Passwort vor dem ersten Deployment!
ADMIN_USERNAME=admin
ADMIN_PASSWORD=change_this_password_immediately

# Enhanced Security (NEW)
# Use hashed password for better security (generate with: python -c "from app.auth_enhanced import hash_password; print(hash_password('your-password'))")
ADMIN_PASSWORD_HASH=

# Session configuration
SESSION_EXPIRY_HOURS=24

# Two-Factor Authentication (2FA)
REQUIRE_2FA=false

# Application Domain
# F√ºr lokale Entwicklung: 127.0.0.1
# F√ºr Produktion: deine-domain.de (ohne http/https)
APP_DOMAIN=127.0.0.1

# Default Profile Settings (optional - wird beim ersten Start verwendet)
# Diese Werte werden nur verwendet, wenn die Datenbank neu initialisiert wird
DEFAULT_PROFILE_NAME=Eric | Tech & Gaming
DEFAULT_PROFILE_BIO=Tech & Gaming Influencer aus Hamburg üéÆ‚ö° | Ingenieur & Content Creator | √Ñsthetik trifft Innovation

# Database Configuration
# Alle Datenbanken werden im data/ Ordner gespeichert
# Standard-Pfade (k√∂nnen √ºberschrieben werden, aber nicht empfohlen):
# DATA_DIR=data
# DATABASE_FILE=data/linktree.db
# SPECIAL_PAGES_DB=data/special_pages.db
# CUSTOM_PAGES_DB=data/pages.db
# MEDIAKIT_DB=data/mediakit.db

# Logging Configuration
# Log-Level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# JSON Logs f√ºr strukturierte Logging (empfohlen f√ºr Produktion)
# Werte: true, false
JSON_LOGS=false

# Optional: JSONLink API Key
# Falls du einen JSONLink API Key hast f√ºr erweiterte Link-Vorschau
JSONLINK_API_KEY=

# Scraper Configuration
# Maximale Anzahl von Versuchen beim Scraping
SCRAPER_MAX_RETRIES=5

# Basis-Backoff-Zeit in Sekunden (exponentiell)
SCRAPER_BACKOFF_BASE=0.5

# Maximale Backoff-Zeit in Sekunden
SCRAPER_BACKOFF_CAP=10

# TLS-Zertifikat-Verifikation aktivieren
SCRAPER_VERIFY_TLS=true

# Cache-TTL f√ºr Scraping-Ergebnisse in Sekunden (Standard: 3600 = 1 Stunde)
SCRAPER_CACHE_TTL=3600

# Optional: Proxy-Liste f√ºr Scraping (komma-getrennt)
# Beispiel: SCRAPER_PROXIES=http://proxy1:8080,http://proxy2:8080
SCRAPER_PROXIES=

# Browser-based scraping configuration (NEW - f√ºr Shortlinks und Bot-Umgehung)
# Browser-Scraping aktivieren/deaktivieren (Standard: true)
SCRAPER_BROWSER_ENABLED=true

# Browser-Fallback aktivieren wenn Standard-Scraping fehlschl√§gt (Standard: true)
SCRAPER_BROWSER_FALLBACK=true

# Browser-Timeout in Sekunden (Standard: 30)
SCRAPER_BROWSER_TIMEOUT=30

# Browser im Headless-Modus ausf√ºhren (Standard: true, f√ºr Produktion empfohlen)
SCRAPER_BROWSER_HEADLESS=true

# Redis Cache Configuration (NEW - f√ºr Production Performance)
# Redis aktivieren f√ºr distributed caching (empfohlen f√ºr Production)
REDIS_ENABLED=false
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
REDIS_PASSWORD=
REDIS_PREFIX=linkinbio:
